Vertica es un sistema de gestiÃ³n de bases de datos analÃ­ticas columnares diseÃ±ado para gestionar grandes volÃºmenes de datos y consultas complejas. AquÃ­ hay un temario bÃ¡sico a avanzado para aprender sobre Vertica:

Nivel BÃ¡sico:

1. IntroducciÃ³n a Vertica
	* DefiniciÃ³n y caracterÃ­sticas principales.
		* DefiniciÃ³n:
			Vertica: Base de datos en columnas, rÃ¡pida y relacional diseÃ±ada para manejar grandes volÃºmenes de datos para anÃ¡lisis.
			OLAP (del inglÃ©s Online Analytical Processing: procesamiento analÃ­tico en lÃ­nea) es un software para realizar anÃ¡lisis multidimensionales a altas velocidades en grandes volÃºmenes de datos de un almacÃ©n de datos, data mart o algÃºn otro almacÃ©n de datos unificado y centralizado.
			Vertica es un sistema de gestiÃ³n de bases de datos analÃ­ticas columnares diseÃ±ado para manejar grandes volÃºmenes de datos y realizar consultas analÃ­ticas de manera eficiente. Fue desarrollado por Vertica Systems, adquirida posteriormente por Hewlett Packard Enterprise (HPE). Vertica se centra en el rendimiento y la escalabilidad para anÃ¡lisis de datos complejos.
			5-100X faster query response.
			Petabyte* proven scale: *1PB = 1,000,000 GB

			Vertica es una base de datos SQL con baja curva de aprendizaje. Cumple con los estÃ¡ndares ANSI SQL.
				ACID: Atomicidad+Consistencia+Aislamiento+Durabilidad

			La arquitectura de pila completa de nube monolÃ­tica estÃ¡ muerta...

			Vertica es...
				* Libertad de despliegue
				* Modelo de libertad de consumo
				* Todo incluido

			CaracterÃ­sticas:
				* Orientado a columnas
				* SeparaciÃ³n de computo y almacenamiento
					* Eon Mode:
						* Soporta varias tecnologias de almacenamiento
						* Aislamiento de carga de trabajo
						* Escalabilidad extrema
				* Aislamiento de carga de trabajo
				* Al ser hÃ­brido, libertad de infraestructura.
				* AnÃ¡lisis compuesto+ML integrado
				* DiseÃ±o fÃ­sico automÃ¡tico (Vertica Database Designer)

			Rendimiento extremo, gracias a la arquitectura columnar:
				* Menos Entradas/Salidas
				* Mejor rendimiento
				* MÃ¡s eficiente

			Comparativa entre el almacenamiento por filas vs por columnas
				Por columnas: Lee 3 columnas:
						â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”
					---â†’â”‚ AAPL â”‚  â”‚      â”‚  â”‚      â”‚  â”‚      â”‚  â”‚      â”‚  â”‚      â”‚  â”‚      â”‚  â”‚      â”‚   â”‚143.74â”‚  â”‚      â”‚  â”‚      â”‚   â”‚5/06/09â”‚
						â”œâ”€â”€â”€â”€â”€â”€â”¤  â”‚ NQDS â”‚  â”‚ NQDS â”‚  â”‚ NQDS â”‚  â”‚ NQDS â”‚  â”‚ NQDS â”‚  â”‚ NQDS â”‚  â”‚ NQDS â”‚   â”œâ”€â”€â”€â”€â”€â”€â”¤  â”‚ NQDS â”‚  â”‚ NQDS â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”¤
						â”‚ AAPL â”‚  â”‚ NYSE â”‚  â”‚ NYSE â”‚  â”‚ NQDS â”‚  â”‚ NYSE â”‚  â”‚ NYSE â”‚  â”‚ NYSE â”‚  â”‚ NYSE â”‚   â”‚143.75â”‚  â”‚ NYSE â”‚  â”‚ NQDS â”‚   â”‚5/06/09â”‚
					----â”œâ”€â”€â”€â”€â”€â”€â”¤--â”‚      â”‚--â”‚      â”‚--â”‚      â”‚--â”‚      â”‚--â”‚      â”‚--â”‚      â”‚--â”‚      â”‚--â†’â”œâ”€â”€â”€â”€â”€â”€â”¤  â”‚      â”‚  â”‚      â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”¤
						â”‚ BBY  â”‚  â”‚ NYSE â”‚  â”‚ NYSE â”‚  â”‚ NYSE â”‚  â”‚ NQDS â”‚  â”‚ NYSE â”‚  â”‚ NYSE â”‚  â”‚ NYSE â”‚   â”‚ 37.03â”‚  â”‚ NYSE â”‚  â”‚ NYSE â”‚   â”‚5/06/09â”‚
						â”œâ”€â”€â”€â”€â”€â”€â”¤  â”‚ NYSE â”‚  â”‚ NYSE â”‚  â”‚ NYSE â”‚  â”‚ NQDS â”‚  â”‚ NYSE â”‚  â”‚ NYSE â”‚  â”‚ NYSE â”‚   â”œâ”€â”€â”€â”€â”€â”€â”¤  â”‚ NYSE â”‚  â”‚ NYSE â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”¤
					----â”‚ BBY  â”‚--â”‚      â”‚--â”‚      â”‚--â”‚      â”‚--â”‚      â”‚--â”‚      â”‚--â”‚      â”‚--â”‚      â”‚---â”‚ 37.13â”‚--â”‚      â”‚--â”‚      â”‚--â†’â”‚5/06/09â”‚
						â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”˜
				Por filas: Lee TODAS las columnas:
						â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
					---â†’â”‚ AAPL  NQDS  NQDS  NQDS  NQDS  NQDS  NQDS  NQDS 143.74 NQDS  NQDS 5/06/09â”‚
						â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
					---â†’â”‚ AAPL  NYSE  NYSE  NQDS  NYSE  NYSE  NYSE  NYSE 143.75 NYSE  NQDS 5/06/09â”‚
						â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
					---â†’â”‚ BBY   NYSE  NYSE  NYSE  NQDS  NYSE  NYSE  NYSE  37.03 NYSE  NYSE 5/06/09â”‚
						â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
					---â†’â”‚ BBY   NYSE  NYSE  NYSE  NQDS  NYSE  NYSE  NYSE  37.13 NYSE  NYSE 5/06/09â”‚
						â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
				SELECT avg(price)
					FROM tickstore_table
					WHERE symbol = 'APPL' AND date '5/06/09';

			ROS (Vertica native format).
				"ROS" en el contexto de Vertica se refiere a "Read-Optimized Storage" (Almacenamiento Optimizado para Lectura). Es un formato de almacenamiento nativo de Vertica que se utiliza para organizar y almacenar fÃ­sicamente los datos en una forma optimizada para operaciones de lectura eficientes.

				CaracterÃ­sticas clave de ROS (Read-Optimized Storage):
					1. Almacenamiento Columnar:
						* Al igual que el modelo de datos de Vertica, el formato ROS organiza los datos de manera columnar en lugar de por filas. Cada columna se almacena de manera independiente, lo que facilita el acceso rÃ¡pido a columnas especÃ­ficas durante las operaciones de lectura.
					2. CompresiÃ³n Eficiente:
						* ROS aplica tÃ©cnicas de compresiÃ³n especÃ­ficas para columnas, lo que reduce el espacio de almacenamiento necesario y mejora la eficiencia en la transmisiÃ³n de datos desde el almacenamiento a la memoria durante las operaciones de lectura.
					3. Proyecciones:
						* Vertica utiliza proyecciones para organizar fÃ­sicamente los datos en el almacenamiento segÃºn las consultas comunes. Estas proyecciones se basan en el formato ROS y permiten optimizar el rendimiento de las consultas mediante la preorganizaciÃ³n de los datos.
					4. IndizaciÃ³n y Metadatos:
						* El formato ROS incluye Ã­ndices y metadatos necesarios para facilitar un acceso rÃ¡pido y eficiente a los datos durante las operaciones de lectura.
					5. Optimizado para Lecturas Secuenciales:
						* El formato ROS estÃ¡ diseÃ±ado para optimizar las operaciones de lectura secuencial, lo que lo hace adecuado para consultas analÃ­ticas que implican exploraciÃ³n de grandes conjuntos de datos.
					6. Procesamiento en Paralelo:
						* ROS se integra con la arquitectura de procesamiento en paralelo de Vertica, lo que permite realizar operaciones de lectura en paralelo para mejorar el rendimiento.
					En resumen, ROS (Read-Optimized Storage) es el formato de almacenamiento nativo de Vertica diseÃ±ado especÃ­ficamente para proporcionar un rendimiento optimizado durante las operaciones de lectura, que son comunes en entornos analÃ­ticos y de data warehousing. Su estructura columnar, compresiÃ³n eficiente y organizaciÃ³n optimizada facilitan el acceso rÃ¡pido a los datos durante las consultas analÃ­ticas.

			Automatice y simplifique el diseÃ±o de modelos fÃ­sicos - Database Designer

			How we use Vertica at GSN (http://willsllc.github.io/blog/how-we-use-vertica-at-gsn/):
				Vertica es rÃ¡pido...
					MySQL: ~24hrs
					Vertica: 1.4s (con una huella de HW mucho menor)

					SELECT
						hr AS "Hours Until Drawing",
						1.0 * cumulative/first_value(cumulative) OVER(ORDER BY hr DESC) AS "Cumulative Percent",
						1.0 * entered/first_value(cumulative) OVER(ORDER BY hr DESC) AS "Hourly Percent"
					FROM (
						SELECT
							datediff('hour', attr31, event_time) AS hr,
							COUNT(DISTINCT fb_user_id) AS entered,
							SUM(COUNT(DISTINCT fb_user_id)) OVER (ORDER BY datediff('hour', attr31, event_time) ASC) AS cumulative
						FROM newapi.events
						WHERE event_type_id=137
							AND datediff('hour', attr31, event_time) BETWEEN -24 AND -1
							AND event_time BETWEEN '2012-10-10' AND date_trunc('day', sysdate)
						GROUP BY 1
					) Z
					ORDER BY 1 ASC;
					Vertica: 100 bln registros y 300ms

			Rendimiento extremo gracias al procesamiento paralelo masivo:
				De toda la data en un solo medio:
					ğŸ›¢
				A multiples medios:
					â”Œâ”€â”€â”€â”€â”€â”€â”€â”
					â”‚Clusterâ”‚
					â”‚â”Œâ”€â”€â”€â”€â” â”‚
					â”‚â”‚ â› â”‚â”€â”¼â”€â”
					â”‚â””â”€â”€â”€â”€â”˜ â”‚ â”‚
					â”‚â”Œâ”€â”€â”€â”€â” â”‚ â””â”€â†’ RE
					â”‚â”‚ â› â”‚â”€â”¼â”€â”€â”€â†’ SU
					â”‚â””â”€â”€â”€â”€â”˜ â”‚ â”Œâ”€â†’ LT
					â”‚â”Œâ”€â”€â”€â”€â” â”‚ â”‚
					â”‚â”‚ â› â”‚â”€â”¼â”€â”˜
					â”‚â””â”€â”€â”€â”€â”˜ â”‚
					â””â”€â”€â”€â”€â”€â”€â”€â”˜
				Y RAID para alta disponibilidad (Backup):
				  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”
				  â”‚ â”‚Clusterâ”‚
				  â”‚ â”‚â”Œâ”€â”€â”€â”€â” â”‚
				  â”‚ â”‚â”‚ â› â”‚â”€â”¼â”€â”
				  â””â”€â”¼â”¼â†’â› â”‚ â”‚ â”‚
					â”‚â””â”€â”€â”€â”€â”˜ â”‚ â”‚
					â”‚â”Œâ”€â”€â”€â”€â” â”‚ â””â”€â†’ RE
					â”‚â”‚ â› â”‚â”€â”¼â”€â”€â”€â†’ SU
					â”‚â”‚ â› â”‚ â”‚
					â”‚â””â”€â”€â”€â”€â”˜ â”‚ â”Œâ”€â†’ LT
					â”‚â”Œâ”€â”€â”€â”€â” â”‚ â”‚
					â”‚â”‚ â› â”‚â”€â”¼â”€â”˜
					â”‚â”‚ â› â”‚ â”‚
					â”‚â””â”€â”€â”€â”€â”˜ â”‚
					â””â”€â”€â”€â”€â”€â”€â”€â”˜

			Â¿QuÃ© nos hace preparados para el futuro?
				Le permite tener libertad de selecciÃ³n de la infraestructura subyacente.

			Cloud, Kubernetes and On-Prem...
				* Vertica en las nubes (Clouds):
					* AWS
					* Google Cloud
					* Azure
					* etc.
					Implementable en instancias de VM en la nube o instancias bare metal en la nube
				* Vertica en el Modo Eon en las nubes (Clouds):
					* AWS
					* Google Cloud
					* Azure
					SeparaciÃ³n del cÃ¡lculo del almacenamiento en instancias de VM en la nube o instancias bare metal en la nube o K8s
				* Vertica On-Premises:
					* Deployable on commodity hardware or virtual machines container (1-node)*
				* Vertica en el Modo Eon On-Premises:
					* SeparaciÃ³n de la computaciÃ³n del almacenamiento en centros de datos locales en hardware bÃ¡sico o mÃ¡quinas virtuales o K8
				* Aceledador Vertica Vertica-as-a-Service:
					* Implementable en tipos predefinidos de instancias de VM en la nube, administradas por Vertica pero en el espacio del Cliente

			Vertica Eon. Aislar cargas de trabajo y necesidades comerciales:
				      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
				 â”Œâ†’ * â”‚Object Storeâ”‚
				 â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
				 â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
				 â”‚    â”‚Data Loading 24x7â”‚
				 â”‚    â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
				 â”‚    â”‚â”‚Compute Nodeâ”‚ï¿©â” â”‚
				 â”‚    â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
				 â”‚    â”‚          â”Œâ”€â”€â”€â”€â”€â”â”‚
				 â”œâ”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚Cacheâ”‚â”‚
				 â”‚    â”‚          â””â”€â”€â”€â”€â”€â”˜â”‚
				 â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
				 â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”€â”€â”
				 â”‚    â”‚Business Intelligenceâ”‚   â”‚
				 â”‚    â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
				 â”‚    â”‚â”‚Compute Nodeâ”‚ï¿©â”     â”‚   â”‚
				 â”‚    â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â”‚   â”‚
				 â”‚    â”‚          â”Œâ”€â”€â”€â”€â”€â”    â”‚   â”‚
				 â”œâ”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚Cacheâ”‚    â”‚   â”‚
				 â”‚    â”‚          â””â”€â”€â”€â”€â”€â”˜    â”‚   â”‚
				 â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”œâ”€ EDW 9x5
				 â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
				 â”‚    â”‚     IT Admin    â”‚       â”‚
				 â”‚    â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚       â”‚
				 â”‚    â”‚â”‚Compute Nodeâ”‚ï¿©â” â”‚       â”‚
				 â”‚    â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚       â”‚
				 â”‚    â”‚          â”Œâ”€â”€â”€â”€â”€â”â”‚       â”‚
				 â”œâ”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚Cacheâ”‚â”‚       â”‚
				 â”‚    â”‚          â””â”€â”€â”€â”€â”€â”˜â”‚       â”‚
				 â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”€â”€â”€â”€â”€â”€â”˜
				 â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
				 â”‚    â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”€â”€â”€â”€â”€â”€â”                  â”‚
				 â”‚    â”‚â”‚Data Science 9x5 â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚â”‚Compute Nodeâ”‚ï¿©â” â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚          â”Œâ”€â”€â”€â”€â”€â”â”‚       â”‚                  â”‚
				 â”œâ”€â”€â”€â”€â”‚â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚Cacheâ”‚â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚          â””â”€â”€â”€â”€â”€â”˜â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚â”‚Compute Nodeâ”‚ï¿©â” â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚          â”Œâ”€â”€â”€â”€â”€â”â”‚       â”œâ”€ Data Lake # SLA â”œâ”€ Kubernetes
				 â”œâ”€â”€â”€â”€â”‚â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚Cacheâ”‚â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚          â””â”€â”€â”€â”€â”€â”˜â”‚       â”‚                  â”‚
				 â”‚    â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚                  â”‚
				 â”‚    â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚                  â”‚
				 â”‚    â”‚â”‚   Sandbox 9x2   â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚â”‚Compute Nodeâ”‚ï¿©â” â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚       â”‚                  â”‚
				 â”‚    â”‚â”‚          â”Œâ”€â”€â”€â”€â”€â”â”‚       â”‚                  â”‚
				 â””â”€â”€â”€â”€â”‚â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚Cacheâ”‚â”‚       â”‚                  â”‚
				      â”‚â”‚          â””â”€â”€â”€â”€â”€â”˜â”‚       â”‚                  â”‚
				      â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”€â”€â”€â”€â”€â”€â”˜                  â”‚
				      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
				A continuaciÃ³n te explicarÃ© el anterior diagrama:
					* El anterior diagrama es una implementaciÃ³n especÃ­fica que permite la separaciÃ³n de almacenamiento y cÃ³mputo.
						* Componentes Principales:
							1. Vertica Eon:
								* Es probable que este sea el sistema principal que utiliza la arquitectura Eon de Vertica, que permite separar el almacenamiento y el cÃ³mputo para escalar y administrar mejor los recursos.
							2. Object Store:
								* El Object Store es donde se almacenan los datos de manera duradera. En la arquitectura Eon, el almacenamiento se externaliza y utiliza un objeto de almacenamiento como S3 de Amazon o Azure Blob Storage.
						* Ãreas de Negocio y Nodos:
							1. Data Loading 24x7:
								* Ãrea dedicada a la carga continua de datos, 24 horas al dÃ­a, 7 dÃ­as a la semana.
							2. EDW 9x5 (Enterprise Data Warehouse):
								* Incluye dos Ã¡reas:
									* Business Intelligence.
									* IT Admin.
								* Estas Ã¡reas estÃ¡n relacionadas con el almacÃ©n de datos empresariales y operan de 9 a 5.
							3. Data Science 9x5:
								* Ãrea especÃ­fica para operaciones de ciencia de datos, operando de 9 a 5.
							4. Sandbox 9x2:
								* Ãrea dedicada a entornos de prueba y desarrollo, operando de 9 a 2.
						* Data Lake # SLA:
							* Parece que "Data Lake # SLA" es una entidad mÃ¡s amplia que incluye "Data Science 9x5" y "Sandbox 9x2".
							* EstÃ¡ implementado en un entorno Kubernetes, sugiriendo una orquestaciÃ³n y gestiÃ³n de contenedores para estas Ã¡reas.
						* Flujos y Conectividad:
							* Todos los flujos de datos (full duplex) se dirigen hacia el Object Store, indicando que el almacenamiento es centralizado en este componente.
							* Cada Ã¡rea de negocio tiene sus propios nodos, y estos nodos a su vez pueden tener cachÃ©s para mejorar el rendimiento.
						* Observaciones:
							* La separaciÃ³n de Ã¡reas como Business Intelligence, IT Admin, Data Science y Sandbox en distintos nodos sugiere una arquitectura que puede escalar y asignar recursos de manera flexible segÃºn las necesidades de cada Ã¡rea.
							* El uso de Kubernetes para "Data Lake # SLA" indica un enfoque moderno y escalable para la gestiÃ³n de contenedores en entornos de ciencia de datos y sandbox.
							* La arquitectura parece estar diseÃ±ada para ofrecer flexibilidad y eficiencia en la gestiÃ³n de cargas de trabajo especÃ­ficas en entornos de anÃ¡lisis de datos y ciencia de datos.
					En general, la arquitectura parece estar diseÃ±ada para ofrecer flexibilidad, escalabilidad y eficiencia en la gestiÃ³n de cargas de trabajo especÃ­ficas en entornos de anÃ¡lisis de datos y ciencia de datos.

			Vertica fuera de la caja...
				Analitica y ML:
					0. Business Understanding
						* Apache Spark
							* Utilizado para procesamiento de datos y anÃ¡lisis.
						* TensorFlow:
							* Marco de trabajo popular para aprendizaje profundo y machine learning.
						* PMML:
							* Formato estÃ¡ndar para representar modelos predictivos.
					1. Data Analytics/Exploration
						* Una serie de tÃ©cnicas y herramientas para explorar y analizar datos, incluyendo:
							* ResÃºmenes estadÃ­sticos (Statistical Summary)
							* DetecciÃ³n de valores atÃ­picos (Outlier Detection)
							* SesionalizaciÃ³n (Sessionization)
							* Coincidencia de patrones (Pattern Matching)
							* Matrices de correlaciÃ³n (Correlation Matrices)
							* Window/Partition
							* Manejo de tipos de fecha (Date Type Handling)
							* Secuencias (Sequences)
							* y mÃ¡s...
					2. Data Preparation
						* Diversas tÃ©cnicas de preparaciÃ³n de datos, como:
							* Series temporales (Time Series)
							* ImputaciÃ³n de valores faltantes (Missing Value Imputation)
							* NormalizaciÃ³n (Normalization)
							* Procesamiento de datos desbalanceados (Imbalanced Data Processing)
							* Muestreo (Sampling)
							* DivisiÃ³n de prueba/validaciÃ³n (Test/Validation Split)
							* Filtrado (Filtering)
							* SelecciÃ³n de caracterÃ­sticas (Feature Selection)
							* Ãlgebra de fecha/hora (Date/Time Algebra)
							* y mÃ¡s...
					3. Model Training
						* Algoritmos de entrenamiento de modelos, incluyendo:
							* XGBoost
							* Bosques aleatorios (Random Forests)
							* K-Means
							* MÃ¡quinas de soporte vectorial (Support Vector Machines)
							* Regresiones logÃ­sticas, lineales, de Ridge (Logistic, Linear, Ridge Regression)
							* Naive Bayes
							* AnÃ¡lisis de componentes principales (Principal Component Analysis)
							* y mÃ¡s...
					4. Model Evaluation
						* EvaluaciÃ³n de modelos con mÃ©tricas como:
							* EstadÃ­sticas a nivel de modelo (Model-level Stats)
							* Tablas ROC (ROC Tables)
							* Tasa de error (Error Rate)
							* Tabla de Levantamiento (Lift Table)
							* Matriz de confusiÃ³n (Confusion Matrix)
							* R-cuadrado (R-Squared)
							* Error cuadrÃ¡tico medio (MSE)
							* ValidaciÃ³n cruzada (Cross Validation)
							* y mÃ¡s...
					5. Deployment/Management
						* Despliegue y gestiÃ³n de modelos, incluyendo:
							* PuntuaciÃ³n en la base de datos (In-Database Scoring)
							* ImportaciÃ³n/exportaciÃ³n de PMML (PMML Import/Export)
							* ImportaciÃ³n de TensorFlow (TensorFlow Import)
							* Velocidad a escala (Speed at Scale)
							* Seguridad
							* GestiÃ³n tipo tabla (Table-Like Management)
							* Versionado
							* AutorizaciÃ³n
							* y mÃ¡s...
					Vertica proporciona soporte para todo el proceso de aprendizaje automÃ¡tico (Machine Learning) desde el entendimiento del negocio hasta la implementaciÃ³n y gestiÃ³n de modelos. Proporciona herramientas y capacidades para cada etapa del flujo de trabajo de machine learning.
					Este enfoque integral permite utilizar Vertica como una plataforma central para el desarrollo y despliegue de modelos de aprendizaje automÃ¡tico en un entorno empresarial.
					En el aprendizaje automÃ¡tico de bases de datos, no hay movimiento de entrada y salida de datos.

			AnÃ¡lisis compuesto y aprendizaje automÃ¡tico. Incorporado (listo para usar):
				143: Popular data virtualisation layer:
				144: Very mature MPP on-prem DB
				149: MPP db
				190: Ingres Descendant
				195: On-Prem DB
				197: Column Based Niche Player
				229: Popular Cloud MPP db
				237: In-Memory Analytics SQL db
				266: Popular Cloud MPP db
				288: Another, Sybase descendant Big Shot
				329: Another of the  old Big Shots
				331: One of the old Big Shots
				383: Popular Cloud MPP db
				533: Popular open source MPP db
				613: Vertica 9.3.1.
				651: Vertica 10.1
				657: Vertica 11.0
				700 ---------- Cuidado con la brecha ----------
				NÃºmero de funciones disponibles segÃºn la documentaciÃ³n del producto.

			Vertica 65%-85%: Tiempo dedicado a explorar y preparar los datos.

			Warta: ...con Vertica nuestros Analistas y CientÃ­ficos de Datos no tienen miedo de experimentar, porque saben que no perderÃ¡n grandes cantidades de tiempo en la exploraciÃ³n y preparaciÃ³n de datos.

			Euro Information: Aprovechando el aprendizaje automÃ¡tico en la base de datos [con Vertica], ahora admitimos casos de uso que antes no podÃ­amos manejar.
				Gaetan Dion, Project Manager, Big Data & Machine Learning

			Mercado de Vertica:
				* Apache Airflow
				* DataHub
				* Grafana
				* Apache Nifi
				* dbt
				* Kafka
				* Apache Spark
				* y mÃ¡s...

			Cumplimiento y Gobernanza:
				* FIPS Validated 140-2
				* ISO 27001 Certified by Shellman
				* SOC 2 Type 2. AICPA SOC
				* ANSI SQL standars
				Vertica puede cumplir fÃ¡cilmente algunos requisitos del RGPD (con herramientas de terceros)

			Vertica permite anÃ¡lisis orientados al dominio:
				(Business Analysts) AND (Data Science & Statisticians) AND (Business Users):
					* DWH, ODS, Data Lake
					* 360 - Data Science
					* Fraud Prevention
					* Next Best Action
					* Data Exploration
					* Churn
					* Customer Experience
					* Pricing Optimization
					Varias herramientas de informes, BI y ciencia de datos

			Powered by Vertica. Performance-Scale:
				* theTradeDesk:
					* Industria: Publicidad.
					* Caso de Uso: AnÃ¡lisis de datos en la industria de la publicidad a una escala de petabytes (Advertising industry data analysis at Petabyte scale)
				* The Climate Corporation:
					* Industria: Agricultura, Clima, Internet de las cosas (IoT).
					* Caso de Uso: AnÃ¡lisis de datos meteorolÃ³gicos y de IoT (Weather and IoT data analytics)
				* Guess:
					* Industria: Minorista, Moda.
					* Caso de Uso: Recomendaciones de productos (Product recommendations)
				* Philips:
					* Industria: Salud, FabricaciÃ³n.
					* Caso de Uso: Mantenimiento predictivo para lograr cero tiempos de inactividad no planificados (Zero unplanned downtimes with predictive maintenance)
				* United Group:
					* Industria: Medios, Publicidad.
					* Caso de Uso: Publicidad en televisiÃ³n dirigida (Addressable TV advertising)
				* Taboola:
					* Industria: Medios, Publicidad.
					* Caso de Uso: Compromiso del pÃºblico (Audience engagement)
				Los lÃ­deres confÃ­an y ganan con Vertica
				Este fragmento resalta ejemplos de casos de uso y organizaciones que se benefician de las capacidades de Vertica, un sistema de gestiÃ³n de bases de datos analÃ­ticas.

			Â¿Porque Vertica?
				Las necesidades del cliente y las fortalezas de Vertica
				* Alto rendimiento
				* Configurabilidad/OptimizaciÃ³n
				* Capacidad para operar en infraestructura compleja
				* Precios transparentes y predecibles
				* Capacidades combinadas y ecosistema de socios

			Sportium: Quedamos impresionados con la increÃ­ble velocidad de carga de datos de Vertica. PodrÃ­amos consultar nuestras gigantescas tablas de datos muy rÃ¡pidamente, filtrando por cualquier columna, sin necesidad de indexar los datos.
				Abel MartÃ­nez, BI Manager

			Algunas caracterÃ­sticas "chidas" de Vertica:
				* Automatic Data Marts (Flattened Tables) / Data Marts automÃ¡ticos (tablas aplanadas)
					ALTER TABLE books
						ADD COLUMN author VARCHAR(50)
						DEFAULT USING (
							SELECT name
								FROM authors
								WHERE id = books.author_id
						);
					Cualquier expresiÃ³n, no solo una bÃºsqueda desde una dimensiÃ³n.
					Â¿Insertar en los hechos? Â¡Se completa automÃ¡ticamente!
					Â¿Se cambiÃ³ la tabla de dimensiones?
						SELECT refresh_column(table, cols)
						Actualiza una sola columna, Â¡incluso por particiÃ³n!
				* Pre-Aggregation for Cubes / PreagregaciÃ³n de cubos
					* Acelere ROLAP aÃºn mÃ¡s agregando Live Aggregate Projection
					CREATE PROJECTION clicks_agg AS
						SELECT page_id,
							click_time::DATE click_date,
							COUNT(*) num_clicks
						FROM clicks
						GROUP BY page_id, click_time::DATE
						KSAFE 1;

						El parÃ¡metro "KSAFE" se refiere al nÃºmero de nodos de respaldo en un clÃºster de Vertica. En este caso, "KSAFE 1" significa que hay un nodo de respaldo.
						En Vertica, la redundancia se logra mediante la replicaciÃ³n de datos en varios nodos del clÃºster, y "KSAFE" especifica cuÃ¡ntos nodos de respaldo deberÃ­an tener los datos. En este caso, "KSAFE 1" indica que cada conjunto de datos en el clÃºster tendrÃ¡ un nodo de respaldo.
						El comando "CREATE PROJECTION" se utiliza para crear una proyecciÃ³n en Vertica, que es un mecanismo para preagregar y organizar fÃ­sicamente los datos para acelerar ciertas consultas. La inclusiÃ³n de "KSAFE 1" indica que se desea un nodo de respaldo para esta proyecciÃ³n, lo que proporciona redundancia en caso de fallos del nodo principal.

						Acelere las consultas con agregados.
						Evite leer GB de detalles en cada consulta.
						Se utiliza automÃ¡ticamente cuando corresponde.
						Similar al almacenamiento en cachÃ© agregado en OLAP, Â¡pero en la base de datos!
				* Find pattern in your data / Encuentra un patrÃ³n en tus datos
					* ...
				* Freedom from Underlying Storage (Tiering) / Libertad de almacenamiento subyacente (niveles)
				* All You for IoT & Clickstream
				* UDX - Unlimited Vertica Expansion
				* GeoSpatial analytics

			https://academy.vertica.com/path-player?courseid=vertica-explained-00&unit=6319e121301a3c149e3034dbUnit
		* Modelo de datos:
			Vertica utiliza un modelo de datos columnar para almacenar y gestionar la informaciÃ³n. Este enfoque difiere del modelo de datos tradicional basado en filas que se encuentra en la mayorÃ­a de las bases de datos relacionales. AquÃ­ hay algunas caracterÃ­sticas clave del modelo de datos columnar en Vertica:
				1. Almacenamiento Columnar:
					* Los datos se almacenan en columnas en lugar de filas.
					* Cada columna se almacena por separado, lo que permite un acceso mÃ¡s eficiente a datos especÃ­ficos durante las consultas.
				2. CompresiÃ³n de Datos:
					* Vertica utiliza algoritmos de compresiÃ³n especÃ­ficos para columnas.
					* La compresiÃ³n reduce el espacio de almacenamiento y mejora el rendimiento al reducir la cantidad de datos que se deben leer desde el disco.
				3. Proyecciones:
					* Vertica utiliza el concepto de proyecciones para organizar y optimizar el almacenamiento fÃ­sico de los datos, para consultas especÃ­ficas, mejorando asÃ­ el rendimiento.
					* Las proyecciones son vistas virtuales de los datos que permiten a la base de datos acceder rÃ¡pidamente a la informaciÃ³n necesaria para consultas especÃ­ficas.
				4. Ãndices:
					* Aunque Vertica no utiliza Ã­ndices tradicionales como las bases de datos relacionales, tiene mecanismos para acelerar las consultas, como el uso de proyecciones y tÃ©cnicas de ordenaciÃ³n.
				5. Particionamiento:
					* Vertica permite el particionamiento de tablas, lo que significa que grandes conjuntos de datos se pueden dividir en particiones mÃ¡s pequeÃ±as, facilitando la administraciÃ³n y mejorando el rendimiento.
				6. OrdenaciÃ³n:
					* Los datos pueden organizarse fÃ­sicamente en funciÃ³n de una o mÃ¡s columnas, lo que facilita la bÃºsqueda y el filtrado basado en esas columnas.
			El modelo de datos columnar de Vertica estÃ¡ diseÃ±ado para optimizar el rendimiento de consultas analÃ­ticas y operaciones de anÃ¡lisis en entornos de grandes volÃºmenes de datos. Este enfoque es especialmente eficaz para casos de uso en los que se realizan consultas complejas y agregaciones sobre conjuntos de datos extensos.
		* ADBMS:
			* La contracciÃ³n comÃºnmente utilizada para "analytic database management" es "ADBMS", que significa "Analytic Database Management System". Esta sigla se refiere a sistemas de gestiÃ³n de bases de datos diseÃ±ados especÃ­ficamente para admitir operaciones analÃ­ticas y consultas complejas en grandes volÃºmenes de datos. Un ejemplo de ADBMS es Vertica, que mencionamos anteriormente.
			* Vertica estÃ¡ diseÃ±ado principalmente para cargas de trabajo analÃ­ticas y consultas complejas en grandes volÃºmenes de datos. Aunque mantiene algunos conceptos de bases de datos relacionales, su enfoque es mÃ¡s analÃ­tico y orientado al rendimiento.
		* DesnormalizaciÃ³n Controlada:
			* A diferencia de la normalizaciÃ³n extensiva en las bases de datos relacionales, Vertica a menudo favorece la desnormalizaciÃ³n controlada para optimizar el rendimiento analÃ­tico. Esto puede incluir redundancias controladas en la estructura de la base de datos para mejorar la eficiencia de las consultas.
		* Alto Rendimiento:
			* Utiliza tÃ©cnicas como el procesamiento en paralelo y la compresiÃ³n de datos para proporcionar un alto rendimiento en consultas analÃ­ticas complejas.
		* Escalabilidad Horizontal:
			* Permite escalar horizontalmente agregando nodos al clÃºster, lo que facilita la expansiÃ³n para manejar grandes volÃºmenes de datos y cargas de trabajo intensivas.
		* Arquitectura MPP (Procesamiento en Paralelo Masivo):
			* Distribuye la carga de trabajo entre mÃºltiples nodos, permitiendo el procesamiento en paralelo de consultas y operaciones.
			* Como los datos se almacenan en columnas y se pueden leer de forma independiente, es mÃ¡s sencillo dividir la carga de trabajo entre mÃºltiples procesadores o nodos, mejorando asÃ­ la velocidad de procesamiento.
		* Carga de Datos RÃ¡pida:
			* Ofrece mÃ©todos eficientes de carga de datos, como la instrucciÃ³n COPY, para la carga masiva y rÃ¡pida de grandes conjuntos de datos.
		* Herramientas Integradas de Machine Learning:
			* Proporciona herramientas integradas para realizar anÃ¡lisis avanzado y machine learning, facilitando el trabajo con datos complejos.
		* IntegraciÃ³n con Herramientas de BI:
			* Compatible con varias herramientas de Business Intelligence (BI), lo que facilita la creaciÃ³n de informes y dashboards.
		* Seguridad Avanzada:
			* Ofrece caracterÃ­sticas de seguridad avanzada, incluyendo autenticaciÃ³n, autorizaciÃ³n y cifrado de datos.
		* Backup y RecuperaciÃ³n Eficientes:
			* Proporciona mecanismos eficientes para realizar copias de seguridad y recuperaciÃ³n de datos, garantizando la integridad y disponibilidad de la informaciÃ³n.
		* Soporte para Datos No Estructurados:
			* Puede manejar datos no estructurados, lo que lo hace versÃ¡til para una variedad de tipos de datos.
		* Adaptabilidad a Grandes Conjuntos de Datos:
			* DiseÃ±ado para rendir bien con grandes conjuntos de datos, especialmente en entornos analÃ­ticos donde las consultas pueden ser complejas y abarcar grandes volÃºmenes de informaciÃ³n.
	* Ventajas de utilizar Vertica en comparaciÃ³n con otras bases de datos.
		* Â¿Por quÃ© el modelo de columnar es mÃ¡s rÃ¡pido que el de filas?
			* El modelo de almacenamiento columnar es mÃ¡s rÃ¡pido que el modelo de almacenamiento por filas en ciertos escenarios, especialmente en el contexto de operaciones analÃ­ticas y consultas que implican agregaciones y selecciones de columnas especÃ­ficas. AquÃ­ hay algunas razones clave por las que el modelo columnar puede ser mÃ¡s eficiente en determinadas situaciones:
				1. Lecturas Selectivas:
					* En operaciones analÃ­ticas, es comÃºn realizar consultas que seleccionan un subconjunto de columnas en lugar de todas las columnas de una fila. En un modelo columnar, los datos de una columna se almacenan juntos, lo que permite lecturas mÃ¡s eficientes de las columnas especÃ­ficas necesarias para una consulta.
				2. CompresiÃ³n Columnar:
					* La compresiÃ³n de datos es mÃ¡s efectiva en un modelo columnar. Dado que los datos similares suelen agruparse en columnas, se pueden aplicar tÃ©cnicas de compresiÃ³n especÃ­ficas a cada columna, reduciendo el espacio de almacenamiento y mejorando la eficiencia en la transmisiÃ³n de datos desde el almacenamiento a la memoria.
				3. Proyecciones y OptimizaciÃ³n:
					* En un sistema como Vertica, se pueden crear proyecciones especÃ­ficas para consultas comunes. Estas proyecciones organizan fÃ­sicamente los datos para mejorar el rendimiento de consultas especÃ­ficas. Como las proyecciones estÃ¡n orientadas a columnas, el modelo columnar facilita esta optimizaciÃ³n.
				4. Operaciones Agregadas Eficientes:
					* Las operaciones analÃ­ticas a menudo implican agregaciones, como sumas y promedios, sobre conjuntos de datos. En un modelo columnar, las operaciones de agregaciÃ³n se pueden realizar mÃ¡s eficientemente, ya que los datos estÃ¡n organizados de manera que las operaciones se aplican a columnas completas en lugar de a filas completas.
				5. Menos E/S en Disco:
					* Al seleccionar solo las columnas necesarias para una consulta, se reduce la cantidad de datos que deben leerse desde el disco. Esto minimiza las operaciones de E/S (entrada/salida), lo que puede ser un factor limitante en el rendimiento.
				Es importante destacar que la eficiencia del modelo columnar depende del tipo de consultas y operaciones que se realicen. En entornos analÃ­ticos, donde las consultas tienden a ser complejas y selectivas, el modelo columnar puede ofrecer un rendimiento significativamente mejor. Sin embargo, en casos de acceso secuencial o actualizaciones frecuentes, el modelo de filas puede ser mÃ¡s apropiado. La elecciÃ³n entre modelos dependerÃ¡ de las necesidades especÃ­ficas del caso de uso.

2. Arquitectura de Vertica
	* Componentes principales: Nodos, ClÃºster, Slices:
		* La arquitectura de Vertica se basa en un diseÃ±o distribuido y en paralelo para proporcionar un alto rendimiento en consultas analÃ­ticas en grandes conjuntos de datos. AquÃ­ estÃ¡n los componentes principales de la arquitectura de Vertica:
			1. Nodos:
				* Un nodo en Vertica es una instancia de software que se ejecuta en una mÃ¡quina fÃ­sica o virtual. Los nodos pueden tener roles diferentes en la arquitectura, como ser nodos de almacenamiento o nodos de consulta.
			2. ClÃºster:
				* Un clÃºster de Vertica estÃ¡ formado por varios nodos que trabajan juntos para proporcionar capacidad de almacenamiento y capacidad de procesamiento en paralelo. Los nodos en un clÃºster pueden escalarse horizontalmente para manejar mayores cargas de trabajo y volÃºmenes de datos.
			3. Slices:
				* Los slices son unidades fundamentales de procesamiento en Vertica y estÃ¡n asociados con nodos de almacenamiento. Cada nodo de almacenamiento se divide en slices, y cada slice es responsable de una porciÃ³n especÃ­fica de los datos almacenados. El procesamiento paralelo se logra distribuyendo consultas entre los slices.
			4. Control de DistribuciÃ³n:
				* En Vertica, se puede especificar cÃ³mo los datos se distribuyen entre los nodos y los slices mediante la elecciÃ³n de una columna de control de distribuciÃ³n. Esto asegura que los datos relevantes para una consulta estÃ©n disponibles localmente en los nodos de almacenamiento adecuados.
			5. Vertica Catalog:
				* El catÃ¡logo de Vertica almacena metadatos sobre la estructura de la base de datos, esquemas, tablas, usuarios, proyecciones y otros objetos. Contiene informaciÃ³n crucial para la administraciÃ³n de la base de datos y se comparte entre todos los nodos del clÃºster.
			6. Herramientas de AdministraciÃ³n:
				* Vertica proporciona herramientas de administraciÃ³n para monitorizar y gestionar el clÃºster. Estas herramientas permiten realizar tareas como la monitorizaciÃ³n del rendimiento, la configuraciÃ³n de recursos y la gestiÃ³n de nodos.
			En resumen, la arquitectura de Vertica se centra en la distribuciÃ³n y el procesamiento en paralelo para lograr un alto rendimiento en entornos analÃ­ticos. La capacidad de escalabilidad horizontal mediante la adiciÃ³n de nodos al clÃºster permite manejar grandes volÃºmenes de datos y cargas de trabajo intensivas de manera eficiente.
	* Modelo de datos columnar y su impacto en el rendimiento:
		* Impacto en el Rendimiento:
			1. Mayor Rendimiento en Consultas AnalÃ­ticas:
				* El acceso eficiente a columnas, la compresiÃ³n de datos y las proyecciones optimizadas contribuyen a un rendimiento mÃ¡s rÃ¡pido en consultas analÃ­ticas, especialmente aquellas que involucran grandes volÃºmenes de datos.
			2. Escalabilidad Horizontal:
				* La arquitectura columnar facilita la escalabilidad horizontal mediante la adiciÃ³n de nodos al clÃºster. Esto permite manejar grandes cargas de trabajo y volÃºmenes de datos a medida que la demanda crece.
			3. Mejora en el Tiempo de Respuesta:
				* Debido a la organizaciÃ³n eficiente de los datos en columnas, Vertica puede proporcionar tiempos de respuesta mÃ¡s rÃ¡pidos en comparaciÃ³n con los modelos de datos basados en filas en entornos analÃ­ticos.

3. InstalaciÃ³n y ConfiguraciÃ³n
	* Requisitos del sistema.
	* Proceso de instalaciÃ³n y configuraciÃ³n bÃ¡sica.

4. CreaciÃ³n de Base de Datos y Tablas
	* Crear una base de datos:
		* En Vertica, la creaciÃ³n de una base de datos implica el uso de comandos SQL. AquÃ­ tienes un ejemplo bÃ¡sico de cÃ³mo crear una base de datos en Vertica:
			-- Crear una base de datos en Vertica
				CREATE DATABASE nombre_de_tu_base_de_datos;
				Sustituye "nombre_de_tu_base_de_datos" con el nombre que deseas darle a tu base de datos.
			AdemÃ¡s, ten en cuenta que para ejecutar comandos SQL en Vertica, necesitas utilizar un cliente SQL compatible con Vertica, como "vsql" (Vertica SQL). Puedes acceder a este cliente a travÃ©s de la lÃ­nea de comandos o mediante herramientas de administraciÃ³n de bases de datos compatibles con Vertica.
			Por ejemplo, para conectarte a tu base de datos reciÃ©n creada usando "vsql", puedes usar el siguiente comando:
				vsql -h nombre_del_host -U nombre_del_usuario -d nombre_de_tu_base_de_datos
				Sustituye "nombre_del_host", "nombre_del_usuario" y "nombre_de_tu_base_de_datos" con los valores apropiados.
			DespuÃ©s de haber creado la base de datos, puedes proceder a crear tablas dentro de ella.
	* DiseÃ±o y creaciÃ³n de tablas:
		-- Crear una tabla en Vertica
			CREATE TABLE nombre_de_tu_tabla (
				columna1 TIPO_DE_DATO,
				columna2 TIPO_DE_DATO,
				...,
				CONSTRAINT nombre_de_tu_constraint PRIMARY KEY (columna1)
			);
			Sustituye "nombre_de_tu_tabla", "columna1", "columna2", "TIPO_DE_DATO" y "nombre_de_tu_constraint" con los nombres y tipos de datos apropiados para tu tabla.
			Recuerda que este es solo un ejemplo bÃ¡sico, y puedes personalizar la estructura de la tabla segÃºn tus necesidades especÃ­ficas. Ten en cuenta que Vertica admite diversos tipos de datos, incluyendo tipos de datos especÃ­ficos de Vertica, como el tipo de datos "TIMESTAMP".
	Una vez que hayas creado la base de datos y las tablas, puedes comenzar a cargar datos, realizar consultas y realizar otras operaciones segÃºn tus requisitos especÃ­ficos.

5. Carga de Datos
	* MÃ©todos de carga de datos: COPY, INSERT, etc.
		* Vertica ofrece varios mÃ©todos para cargar datos en sus tablas, y los dos mÃ©todos principales son "COPY" e "INSERT". AquÃ­ se explica cada uno de ellos:
			1. MÃ©todo "COPY":
				* El mÃ©todo "COPY" es el enfoque preferido para cargar grandes volÃºmenes de datos de manera eficiente en Vertica. Utiliza archivos de datos externos para realizar la carga en paralelo.
				* Ejemplo de uso del comando "COPY":
					-- Ejemplo de COPY para cargar datos desde un archivo CSV
					COPY nombre_de_tu_tabla FROM '/ruta/del/archivo/data.csv' DELIMITER ',' DIRECT;
					* "nombre_de_tu_tabla": Reemplaza esto con el nombre de la tabla en la que deseas cargar los datos.
					* "/ruta/del/archivo/data.csv": Especifica la ruta del archivo de datos externo que contiene los datos a cargar.
					* "DELIMITER ','": Indica el delimitador utilizado en el archivo, en este caso, una coma (','). Ajusta segÃºn el delimitador de tu archivo.
					* "DIRECT": Indica que la carga debe realizarse directamente sin almacenamiento temporal, lo que mejora la eficiencia.
			2. MÃ©todo "INSERT":
				* El mÃ©todo "INSERT" se utiliza para insertar datos en Vertica de manera mÃ¡s tradicional, fila por fila. Este mÃ©todo puede ser adecuado para cargas mÃ¡s pequeÃ±as o cuando los datos provienen de una consulta o procedimiento almacenado.
				* Ejemplo de uso del comando "INSERT":
					-- Ejemplo de INSERT para cargar datos en una tabla
					INSERT INTO nombre_de_tu_tabla (columna1, columna2, ...) VALUES (valor1, valor2, ...);
					* "nombre_de_tu_tabla": Reemplaza esto con el nombre de la tabla en la que deseas cargar los datos.
					* "columna1, columna2, ...": Enumera las columnas en las que deseas insertar datos.
					* "valor1, valor2, ...": Proporciona los valores correspondientes a las columnas enumeradas.
			* Consejo:
				* Si tienes una cantidad significativa de datos para cargar, se recomienda utilizar "COPY" debido a su capacidad para realizar operaciones en paralelo y su eficiencia en la carga masiva de datos.
			Estos son los mÃ©todos principales para cargar datos en Vertica. AdemÃ¡s de estos, Vertica tambiÃ©n proporciona otras opciones y configuraciones especÃ­ficas para la carga de datos que pueden adaptarse a tus necesidades particulares.
		* AdemÃ¡s de los mÃ©todos "COPY" e "INSERT", Vertica proporciona algunas otras opciones y mÃ©todos para cargar datos:
			1. External Tables:
				* Vertica permite la creaciÃ³n de tablas externas que apuntan directamente a archivos de datos en el sistema de archivos sin realizar una carga fÃ­sica en la base de datos. Puedes consultar estos archivos externos como si fueran tablas regulares.
					-- Ejemplo de creaciÃ³n de una External Table
					CREATE EXTERNAL TABLE nombre_de_tu_tabla_external (
						columna1 TIPO_DE_DATO,
						columna2 TIPO_DE_DATO
					)
					LOCATION '/ruta/del/archivo/data.csv' 
					FORMAT 'CSV' 
					DELIMITER ',';
			2. "vsql" y "\COPY":
				* El cliente de lÃ­nea de comandos "vsql" incluye una opciÃ³n "\COPY" que es similar al comando "COPY" de SQL, pero ejecutado desde el cliente de lÃ­nea de comandos. Puedes usar esto para cargar datos desde archivos locales en tu mÃ¡quina a una tabla de Vertica:
					\COPY nombre_de_tu_tabla FROM '/ruta/del/archivo/data.csv' DELIMITER ',';
			3. "INSERT" desde una Consulta:
				* Puedes utilizar una instrucciÃ³n "INSERT" junto con una consulta para cargar datos desde otra tabla o resultado de una consulta:
					INSERT INTO nombre_de_tu_tabla (columna1, columna2, ...)
					SELECT columna1, columna2, ...
					FROM otra_tabla
					WHERE condiciÃ³n;
			4. "vsql -c":
				* Puedes utilizar el cliente "vsql" con la opciÃ³n "-c" para ejecutar comandos SQL directamente desde la lÃ­nea de comandos. Esto puede ser Ãºtil para realizar operaciones de carga en scripts:
					vsql -h nombre_del_host -U nombre_del_usuario -d nombre_de_tu_base_de_datos -c "COPY nombre_de_tu_tabla FROM '/ruta/del/archivo/data.csv' DELIMITER ',' DIRECT;"
			Estas son solo algunas opciones adicionales que pueden ser Ãºtiles dependiendo de tu situaciÃ³n especÃ­fica. La elecciÃ³n del mÃ©todo dependerÃ¡ de factores como la cantidad de datos, la fuente de los datos y tus preferencias operativas.
	* Estrategias de carga masiva y eficiencia:
		Cuando se trata de estrategias de carga masiva y eficiencia en Vertica, es crucial considerar la naturaleza de los datos, el volumen de los mismos y la frecuencia de las operaciones de carga. AquÃ­ hay algunas estrategias y prÃ¡cticas recomendadas para la carga masiva de datos eficiente en Vertica:
			1. Usar "COPY" para Cargas Masivas:
				* La instrucciÃ³n "COPY" es la opciÃ³n preferida para cargar grandes volÃºmenes de datos en Vertica. Utiliza archivos de datos externos para realizar la carga en paralelo, lo que mejora significativamente la eficiencia.
					COPY nombre_de_tu_tabla FROM '/ruta/del/archivo/data.csv' DELIMITER ',' DIRECT;
				* Ajusta las opciones segÃºn tus necesidades, como el delimitador, la ubicaciÃ³n del archivo y la configuraciÃ³n de carga.
			2. Considerar Proyecciones:
				* Antes de cargar datos, asegÃºrate de tener proyecciones Ã³ptimas para las consultas comunes. Puedes crear proyecciones diseÃ±adas especÃ­ficamente para mejorar el rendimiento de las consultas despuÃ©s de cargar los datos.
					-- Crear proyecciÃ³n
					CREATE PROJECTION nombre_de_tu_proyeccion AS SELECT * FROM nombre_de_tu_tabla;
			3. Desactivar Ãndices y Restricciones:
				* Temporalmente desactiva Ã­ndices y restricciones antes de la carga masiva y actÃ­valos nuevamente despuÃ©s. Esto puede mejorar significativamente el rendimiento durante la carga.
					-- Desactivar Ã­ndices y restricciones
					ALTER TABLE nombre_de_tu_tabla DISABLE INDEX, NO FORCE CONSTRAINTS;
			4. Usar Carga en Paralelo:
				* Aprovecha la capacidad de carga en paralelo de Vertica. Si tienes un clÃºster con varios nodos, la carga se distribuirÃ¡ y procesarÃ¡ en paralelo, mejorando la eficiencia.
			5. Carga en Modo Directo:
				* Utiliza la opciÃ³n "DIRECT" con "COPY" para realizar la carga directa sin almacenamiento temporal. Esto mejora la eficiencia al evitar la creaciÃ³n de archivos temporales.
					COPY nombre_de_tu_tabla FROM '/ruta/del/archivo/data.csv' DELIMITER ',' DIRECT;
			6. Monitorear y Ajustar Configuraciones:
				* Monitorea el rendimiento durante la carga y ajusta las configuraciones segÃºn sea necesario. Esto puede incluir ajustar parÃ¡metros como "MaxClientSessions", "MaxMemorySize", entre otros.
			7. Planificar Recargas Incrementales:
				* Si es posible, planifica recargas incrementales en lugar de recargas completas. Esto implica cargar solo los datos nuevos o actualizados, lo que puede ser mÃ¡s eficiente.
			8. Utilizar Herramientas de Carga Especializadas:
				* Considera el uso de herramientas especializadas o integraciones que faciliten la carga masiva de datos en Vertica. Algunas herramientas ETL (Extract, Transform, Load) pueden ofrecer caracterÃ­sticas especÃ­ficas para la carga eficiente en Vertica.
			Estas estrategias y prÃ¡cticas recomendadas son generalizadas, y la elecciÃ³n especÃ­fica dependerÃ¡ de la naturaleza de tu carga de trabajo y de los requisitos de tu aplicaciÃ³n. Realiza pruebas y ajustes para optimizar la carga de datos segÃºn tus necesidades especÃ­ficas.

Nivel Intermedio:

6. OptimizaciÃ³n de Consultas
	* Uso de Ã­ndices y proyecciones.
		En Vertica, la optimizaciÃ³n de consultas es esencial para garantizar un rendimiento eficiente en la recuperaciÃ³n y anÃ¡lisis de datos. El uso de Ã­ndices y proyecciones son dos estrategias clave que Vertica emplea para mejorar el rendimiento de las consultas.
		1. Ãndices en Vertica:
			* Estructuras de Ãndices:
				Vertica utiliza estructuras de Ã­ndices para acelerar la bÃºsqueda y recuperaciÃ³n de datos. Sin embargo, a diferencia de algunos sistemas de bases de datos tradicionales, Vertica utiliza Ã­ndices principalmente para optimizar la velocidad de carga de datos y no tanto para mejorar la velocidad de las consultas de selecciÃ³n.
			* Indices de SincronizaciÃ³n:
				En lugar de Ã­ndices tradicionales, Vertica utiliza Ã­ndices de sincronizaciÃ³n que se crean automÃ¡ticamente para mantener la integridad y consistencia de los datos durante las operaciones de carga.
				Por ejemplo, cuando realizas una operaciÃ³n de carga, Vertica maneja la creaciÃ³n y mantenimiento de estos Ã­ndices para garantizar la coherencia de los datos.
				Ejemplo:
					Supongamos que tienes una tabla grande en Vertica que almacena datos de transacciones financieras. Puedes utilizar Ã­ndices de sincronizaciÃ³n para acelerar la carga de datos, asegurando la consistencia y la integridad durante las operaciones de inserciÃ³n.
					-- Crear una tabla con Ã­ndices de sincronizaciÃ³n
					CREATE TABLE transacciones (
						id INT PRIMARY KEY,
						fecha TIMESTAMP,
						monto DECIMAL(10,2),
						-- Otros campos...
					) ORDER BY fecha;
					En Vertica, la terminologÃ­a puede variar en comparaciÃ³n con otros sistemas de bases de datos. En lugar de Ã­ndices de sincronizaciÃ³n, Vertica utiliza estructuras internas como "Tuple Mover" para gestionar la carga y la eficiencia de las consultas.

					En Vertica, las "Super Proyecciones" y el "Tuple Mover" trabajan de manera conjunta para mantener la eficiencia en la carga y mejorar el rendimiento de las consultas. Los "Super Projections" son proyecciones automÃ¡ticas creadas por Vertica para optimizar consultas, y el "Tuple Mover" es responsable de la transferencia eficiente de datos durante la carga.

					Entonces, en el ejemplo proporcionado, Vertica gestionarÃ­a internamente el proceso de carga y mantenimiento de la consistencia sin necesidad de especificar Ã­ndices de sincronizaciÃ³n manualmente. La optimizaciÃ³n de la carga y el rendimiento de las consultas se logra mediante la combinaciÃ³n de proyecciones y procesos internos de Vertica.
		2. Proyecciones en Vertica:
			* DefiniciÃ³n de Proyecciones:
				Las proyecciones son una caracterÃ­stica clave de Vertica que se utiliza para optimizar las consultas analÃ­ticas. Una proyecciÃ³n es una vista fÃ­sica precalculada y almacenada de los datos que estÃ¡ optimizada para consultas especÃ­ficas.
				Ejemplo:
					Imagina que tienes una tabla de ventas y deseas mejorar el rendimiento de las consultas de anÃ¡lisis. Puedes crear una proyecciÃ³n que estÃ© optimizada para consultas que involucren fechas y montos de venta.
					-- Crear una proyecciÃ³n para optimizar consultas analÃ­ticas
					CREATE PROJECTION sales_projection AS
					SELECT fecha, SUM(monto) AS monto_total
					FROM ventas
					GROUP BY fecha;
			* Columnar Storage:
				Vertica almacena datos de manera columnar, y las proyecciones estÃ¡n diseÃ±adas para aprovechar este almacenamiento. Cada proyecciÃ³n se crea teniendo en cuenta patrones de acceso a los datos, lo que mejora significativamente el rendimiento de las consultas.
				En el ejemplo anterior, la proyecciÃ³n almacena la informaciÃ³n de la fecha y el monto por separado, lo que facilita la lectura eficiente de estos datos.
			* Proyecciones de AgregaciÃ³n:
				Vertica puede crear proyecciones que incluyan datos agregados para reducir la necesidad de realizar cÃ¡lculos durante la ejecuciÃ³n de la consulta.
				Ejemplo:
					Si necesitas calcular el total de ventas por producto, puedes tener una proyecciÃ³n que almacene estos totales precalculados.
					-- Crear una proyecciÃ³n de agregaciÃ³n para mejorar consultas de total de ventas por producto
					CREATE PROJECTION product_sales_total AS
					SELECT producto_id, SUM(monto) AS total_ventas
					FROM ventas
					GROUP BY producto_id;
		Estrategias Adicionales en Vertica:
			* OptimizaciÃ³n del Plan de EjecuciÃ³n:
				Vertica realiza una optimizaciÃ³n dinÃ¡mica del plan de ejecuciÃ³n para adaptarse a los cambios en la distribuciÃ³n de datos y las condiciones del sistema.
			* EstadÃ­sticas y Perfiles de Consulta:
				Utiliza estadÃ­sticas detalladas y perfiles de consulta para analizar el rendimiento de las consultas y ajustar dinÃ¡micamente su plan de ejecuciÃ³n.
			* Uso Eficiente de Recursos:
				Gestiona eficientemente los recursos, incluidos los nodos, clÃºsteres y slices, para distribuir la carga de manera equitativa y maximizar el rendimiento.
		En resumen, Vertica emplea varias estrategias, incluyendo Ã­ndices de sincronizaciÃ³n, proyecciones y optimizaciÃ³n dinÃ¡mica del plan de ejecuciÃ³n, para garantizar un rendimiento eficiente en la recuperaciÃ³n y anÃ¡lisis de datos en entornos analÃ­ticos.
	* Estrategias para escribir consultas eficientes.
		Optimizar consultas en Vertica implica escribir consultas de manera eficiente para aprovechar al mÃ¡ximo la arquitectura de la base de datos y mejorar el rendimiento. AquÃ­ hay algunas estrategias para escribir consultas eficientes en Vertica:
			1. Seleccionar Columnas EspecÃ­ficas:
				* Evitar el Uso de "SELECT *":
					Selecciona solo las columnas necesarias en lugar de usar "SELECT *". Esto reduce la cantidad de datos transferidos y mejora la eficiencia.
					-- Evitar
					SELECT * FROM tabla;
					-- Preferir
					SELECT columna1, columna2 FROM tabla;
			2. Filtrar Datos Eficientemente:
				* Utilizar ClÃ¡usulas "WHERE":
					Filtra los datos en la fase de escaneo utilizando clÃ¡usulas "WHERE" para reducir la cantidad de registros procesados.
					SELECT columna1, columna2 FROM tabla WHERE columna3 = 'valor';
			3. Utilizar Ãndices:
				* Aprovechar Ãndices de BÃºsqueda:
					Utiliza Ã­ndices cuando sea posible para acelerar la bÃºsqueda de datos. Vertica puede crear Ã­ndices de bÃºsqueda para mejorar el rendimiento.
					CREATE INDEX idx_columna ON tabla(columna);
			4. Agregar Columnas de Forma Eficiente:
				* Utilizar Agregaciones de Columnas:
					Utiliza funciones de agregaciÃ³n para calcular sumas, promedios, y otras operaciones directamente en la base de datos, reduciendo la necesidad de procesamiento adicional en la aplicaciÃ³n.
					SELECT SUM(columna) FROM tabla;
			5. Limitar el Uso de "JOIN":
				* Ser Consciente de las Operaciones JOIN:
					Limita el uso de operaciones "JOIN" cuando sea posible y utiliza otras estrategias como proyecciones optimizadas.
					SELECT t1.columna, t2.columna
					FROM tabla1 t1
					INNER JOIN tabla2 t2 ON t1.id = t2.id;
			6. Utilizar Subconsultas con ModeraciÃ³n:
				* Evitar Subconsultas Innecesarias:
					Evita subconsultas innecesarias que puedan afectar el rendimiento. Considera reescribir la consulta para utilizar "JOIN" o agregaciones directamente.
					-- Evitar
					SELECT columna FROM tabla WHERE id IN (SELECT id FROM otra_tabla);
					-- Preferir
					SELECT t1.columna FROM tabla t1 INNER JOIN otra_tabla t2 ON t1.id = t2.id;
			7. Monitoreo y Ajuste:
				* Analizar el Plan de EjecuciÃ³n:
					Utiliza herramientas de monitoreo de rendimiento para analizar los planes de ejecuciÃ³n de las consultas y ajustar segÃºn sea necesario.
					Ejemplo de Consulta Eficiente:
					-- Ejemplo de consulta eficiente
					SELECT fecha, SUM(monto) AS monto_total
					FROM ventas
					WHERE fecha BETWEEN '2022-01-01' AND '2022-01-31'
					GROUP BY fecha;
					Esta consulta selecciona columnas especÃ­ficas, filtra datos eficientemente y utiliza una funciÃ³n de agregaciÃ³n para calcular el total de ventas por fecha. Ajusta estas estrategias segÃºn las necesidades especÃ­ficas de tu aplicaciÃ³n y las caracterÃ­sticas de tu base de datos en Vertica.

7. GestiÃ³n de Usuarios y Permisos
	* Crear y gestionar usuarios.
	* Asignar privilegios y roles.

8. AdministraciÃ³n del Sistema
	* Monitoreo de rendimiento.
	* GestiÃ³n de recursos y configuraciÃ³n avanzada.

9. Backup y RecuperaciÃ³n
	* Estrategias de backup.
	* Procedimientos de recuperaciÃ³n.

Nivel Avanzado:

10. Particionamiento y SegmentaciÃ³n
	* OptimizaciÃ³n avanzada de la estructura de las tablas.
	* Uso de particiones y segmentos.

11. IntegraciÃ³n con Herramientas de BI
	* Conectar Vertica con herramientas de Business Intelligence.
	* CreaciÃ³n de informes y dashboards.

12. GestiÃ³n de Carga de Trabajo
	* GestiÃ³n avanzada de la carga de trabajo.
	* ConfiguraciÃ³n de recursos para optimizar la ejecuciÃ³n de consultas.

13. Seguridad Avanzada
	* ConfiguraciÃ³n de SSL y autenticaciÃ³n avanzada.
	* Estrategias de seguridad para datos sensibles.

14. Desarrollo de UDFs (User-Defined Functions)
	* Crear funciones personalizadas.
	* IntegraciÃ³n de funciones definidas por el usuario en consultas.

15. IntegraciÃ³n con Big Data
	* Conectar Vertica con entornos de Big Data.
	* Estrategias para trabajar con datos distribuidos.

Recuerda que Vertica es una plataforma robusta y compleja, por lo que es recomendable combinar la teorÃ­a con la prÃ¡ctica, realizando ejercicios y proyectos para obtener una comprensiÃ³n profunda de sus capacidades. AdemÃ¡s, consulta siempre la documentaciÃ³n oficial de Vertica para obtener informaciÃ³n actualizada y detallada.
